{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *\n",
    "from fun import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinal_grouped_polygons = 100\n",
    "root = \"data/elevation_files/\"\n",
    "datafilename = \"data/polygons_and_points.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Marks Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks = np.linspace(0,len(df),int(len(df)/cardinal_grouped_polygons)).astype(int)\n",
    "a = marks[:-1]\n",
    "b = marks[1:]\n",
    "marks = np.vstack((a,b))\n",
    "marks = marks.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderfiles = listdir(root)\n",
    "filenames_list = [filename for filename in folderfiles if filename.endswith(\"csv\") ]\n",
    "backfiles = filenames_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation points computed so far :  107607 ( 100.0% ) | errors :  0\n"
     ]
    }
   ],
   "source": [
    "errors_counter = 0\n",
    "errors_list = []\n",
    "points_counter = 0\n",
    "\n",
    "for idxmarker,bornes in enumerate(marks[:]):\n",
    "    start,end = bornes\n",
    "    tempdf = df[start:end]\n",
    "    some_points = tempdf[[\"long\",\"lat\"]].to_dict(orient = \"split\")[\"data\"]\n",
    "    exactfilename = \"file_\" + str(idxmarker).zfill(5) + \"_from_\" + str(start) + \"_to_\" + str(end) + \".csv\"\n",
    "    tempfilename = root + exactfilename\n",
    "    \n",
    "    try:\n",
    "        tempdata = py3dep.elevation_bycoords(some_points,crs=\"epsg:4326\")\n",
    "        exportdf = tempdf.polygonid.to_frame().reset_index(drop=True)\n",
    "        exportdf[\"elevation\"] = tempdata        \n",
    "        need_to_be_zero = exportdf.elevation.isna().sum()\n",
    "        if need_to_be_zero == 0:\n",
    "            exportdf.to_csv(tempfilename,index = False)\n",
    "        else:\n",
    "            errors_counter = errors_counter + 1\n",
    "            errors_list.append((idxmarker,bornes,tempdf))\n",
    "    except:\n",
    "        errors_counter = errors_counter + 1\n",
    "        errors_list.append((idxmarker,bornes,tempdf))\n",
    "\n",
    "    points_counter = points_counter + len(exportdf)\n",
    "    progression = round(100*(points_counter / len(df))  ,  2)\n",
    "    progression = str(progression) + \"%\"      \n",
    "    clear_output(wait=True)\n",
    "    print(\"Elevation points computed so far : \",points_counter,\"(\",progression,\") | errors : \",errors_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( errors_list, open( root + \"errors_list.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute average elevation by block group and save it to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lancer uniquement si l'on n'a pas relancer la construction de l'output avec randompointswithinpooly notebook\n",
    "allids = np.unique(df.polygonid)\n",
    "setids = np.unique(elevation_df.polygonid)\n",
    "remainedids = allids[~np.isin(allids,setids)]\n",
    "tempdf = df[df.polygonid.isin(remainedids)]\n",
    "\n",
    "some_points = tempdf[[\"long\",\"lat\"]].to_dict(orient = \"split\")[\"data\"]\n",
    "tempdata = py3dep.elevation_bycoords(some_points,crs=\"epsg:4326\")\n",
    "\n",
    "toadddf = tempdf.polygonid.to_frame().reset_index(drop=True)\n",
    "toadddf[\"elevation\"] = tempdata\n",
    "\n",
    "folderfiles = listdir(root)\n",
    "filenames_list = [filename for filename in folderfiles if filename.endswith(\"csv\") ]\n",
    "list_of_dataframes = [pd.read_csv(root + tempfilename) for tempfilename in filenames_list]\n",
    "list_of_dataframes.append(toadddf)\n",
    "\n",
    "elevation_df = pd.concat(list_of_dataframes)\n",
    "elevation_dict = elevation_df.groupby(\"polygonid\")[\"elevation\"].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data/polygons_elevation.json', 'w') as f:\n",
    "    json.dump(elevation_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afficher la map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefilename = \"data/polygons/TG00CAGRP.shp\"\n",
    "elevation_json_name = 'data/polygons_elevation.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter part, pour pas avoir 1000 ans avant que ca s'affiche\n",
    "# Point Ã  x,y + rayon de 100 km\n",
    "#centroid_mask = Point(( -118.2987,33.7866)) #LA\n",
    "centroid_mask = Point(( -122.43695509472653,37.75426308044698)) #SF\n",
    "box_mask = centroid_mask.buffer(distance=0.0001)\n",
    "box_mask = Buffer_A_Shape(box_mask,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(elevation_json_name) as json_file:\n",
    "    elevation_data = json.load(json_file)\n",
    "    \n",
    "blocks = fiona.open(shapefilename)\n",
    "blocks_polygons = [shape(item[\"geometry\"]) for item in blocks]\n",
    "blocks_filtered_array = [True if item.within(box_mask) else False for item in blocks_polygons ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_data = [(int(k),v) for k,v in elevation_data.items()]\n",
    "polygondf = pd.DataFrame(elevation_data,columns=[\"polygonid\",\"elevation\"])\n",
    "\n",
    "\n",
    "filterdict = {\"filtered\" : blocks_filtered_array,\n",
    "              \"polygonid\" : list(range(len(blocks_filtered_array)))}\n",
    "filterdf = pd.DataFrame(filterdict)\n",
    "polygondf = polygondf.merge(filterdf,how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION PAS D'ELEVATION POUR CERTAINS POLYGONES, A INVESTIGUER\n",
    "polygondf = polygondf[(~polygondf.elevation.isna()) & (polygondf.filtered)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = min(polygondf.elevation)\n",
    "maxval = max(polygondf.elevation)\n",
    "polygondf[\"elevation_color\"] = ColorMapper(minval,maxval,polygondf.elevation,\"RdYlGn_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation du geojson\n",
    "features = []\n",
    "\n",
    "for rowid,others in polygondf.iterrows():\n",
    "    temp_elevation = others[\"elevation\"]\n",
    "    temp_color = others[\"elevation_color\"]\n",
    "    temp_id = others[\"polygonid\"]\n",
    "    \n",
    "    data = {}\n",
    "    data[\"rowid\"] = int(temp_id)\n",
    "    data[\"fillcolor\"] = str(temp_color)\n",
    "    data[\"fill_opacity\"] = 0.5\n",
    "    data[\"color\"] = \"white\"\n",
    "    data[\"opacity\"] = 0.5\n",
    "    data[\"elevation\"] = int(temp_elevation)\n",
    "    \n",
    "    feature = {\"type\":\"Feature\",\n",
    "               \"properties\":data,\n",
    "               \"geometry\":shapely.geometry.mapping(blocks_polygons[int(temp_id)])}\n",
    "    \n",
    "    features.append(feature)\n",
    "    \n",
    "final_geojson = {\"type\": \"FeatureCollection\",\"features\" : features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.map.LayerControl at 0x7f764e3c8a00>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids_array = [(pp.centroid.xy[-1][-1],pp.centroid.xy[0][-1]) for pp in blocks_polygons]\n",
    "barycentre = np.mean(centroids_array,axis=0)\n",
    "m = folium.Map(location = barycentre, zoom_start= 6,width=\"66%\",tiles=\"Cartodbdark_matter\")\n",
    "\n",
    "stylefun = lambda x: {'fillColor' : x['properties']['fillcolor'],\n",
    "                      'fillOpacity' : x['properties']['fill_opacity'],\n",
    "                     'color' : x['properties']['color'],\n",
    "                     'opacity' : x['properties']['opacity']}\n",
    "\n",
    "folium.GeoJson(data=final_geojson,\n",
    "               style_function= stylefun,\n",
    "               smooth_factor=1,\n",
    "               tooltip=folium.features.GeoJsonTooltip(fields=[\"rowid\",\"elevation\"],\n",
    "                                                      aliases=[\"Polygone ID : \",\"Elevation (meters) : \"])).add_to(m)\n",
    "\n",
    "plugins.Fullscreen().add_to(m)\n",
    "plugins.MeasureControl().add_to(m)\n",
    "folium.TileLayer('openstreetmap').add_to(m)\n",
    "folium.TileLayer('Stamen Terrain').add_to(m)\n",
    "folium.LayerControl().add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geosys",
   "language": "python",
   "name": "geosys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
